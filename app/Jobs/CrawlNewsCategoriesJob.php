<?php

namespace App\Jobs;

use App\Traits\InteractsWithHttp; // âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Trait
use Illuminate\Contracts\Queue\ShouldQueue;
use Illuminate\Foundation\Queue\Queueable;
use Illuminate\Support\Facades\DB;
use Illuminate\Support\Facades\Log;
use Symfony\Component\DomCrawler\Crawler;

class CrawlNewsCategoriesJob implements ShouldQueue
{
    use Queueable, InteractsWithHttp;

    private const RETRY_DELAY = 60;
    private int $siteId;
    private int $categoryId;
    private string $url;
    private string $jobId;

    public function __construct(int $siteId, int $categoryId, string $url)
    {
        $this->siteId = $siteId;
        $this->categoryId = $categoryId;
        $this->url = $url;
        $this->jobId = uniqid('crawl_cat_', true);
    }

    public function handle()
    {
        try {
            // Ø¯Ø±ÛŒØ§ÙØª Ù†Ø§Ù… Ø³Ø§ÛŒØª
            $site = DB::table('news_sites')->find($this->siteId);
            if (!$site) throw new \Exception("Ø³Ø§ÛŒØª ÛŒØ§ÙØª Ù†Ø´Ø¯");

            $siteName = json_decode($site->name)->en ?? 'Unknown';
            $config = config('crawler.sites.' . $siteName);

            if (!$config) throw new \Exception("Ú©Ø§Ù†ÙÛŒÚ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯ Ø¨Ø±Ø§ÛŒ: $siteName");

            Log::info("ðŸ” [Ø´Ø±ÙˆØ¹ Ø®Ø²Ø´ Ø¯Ø³ØªÙ‡]", ['url' => $this->url, 'site' => $siteName]);

            // Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ Ø¨Ø§ Trait
            $response = $this->sendRequest($this->url, 'get', ['job_id' => $this->jobId]);
            $html = $response->body();

            $crawler = new Crawler($html);

            // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
            $links = $crawler->filter($config['category_selectors']['links'])->each(function (Crawler $node) {
                return $this->normalizeUrl($node->attr('href'));
            });

            // Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø®Ø§Ù„ÛŒâ€ŒÙ‡Ø§
            $links = array_unique(array_filter($links));

            // Ø¨Ø±Ø±Ø³ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„Ø§Ù‹ Ú©Ø±ÙˆÙ„ Ø´Ø¯Ù‡
            $existing = DB::table('news')->whereIn('source_url', $links)->pluck('source_url')->toArray();
            $newLinks = array_diff($links, $existing);

            foreach ($newLinks as $link) {
                // ÙÛŒÙ„ØªØ± Ø§Ø¶Ø§ÙÛŒ (Ø§Ú¯Ø± Ø¯Ø± Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø§Ø´Ø¯)
                if (!empty($config['category_selectors']['filter'])) {
                    if (!str_contains($link, $config['category_selectors']['filter'])) continue;
                }

                CrawlNewsContentJob::dispatch(
                    $siteName,
                    $this->siteId,
                    $this->categoryId,
                    $link,
                    $config['news_selectors']
                );
            }

            Log::info("âœ… [Ù¾Ø§ÛŒØ§Ù† Ø®Ø²Ø´ Ø¯Ø³ØªÙ‡]", ['Ú©Ù„ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§' => count($links), 'Ø¬Ø¯ÛŒØ¯' => count($newLinks)]);

        } catch (\Exception $e) {
            Log::error("âŒ [Ø®Ø·Ø§ Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ]", ['url' => $this->url, 'msg' => $e->getMessage()]);
            $this->release(self::RETRY_DELAY);
        }
    }

    private function normalizeUrl(?string $link): string
    {
        if (empty($link)) return '';
        if (str_starts_with($link, 'http')) return $link;

        $parsed = parse_url($this->url);
        $root = $parsed['scheme'] . '://' . $parsed['host'];
        return $root . '/' . ltrim($link, '/');
    }
}
